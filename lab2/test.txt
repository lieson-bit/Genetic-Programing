# –ó–ê–î–ê–ù–ò–ï
–î–∞–Ω –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–π —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –º–æ–¥–µ–ª–∏ –∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –º–æ–¥–µ–ª–∏, —É–∫–∞–∑–∞–Ω–Ω–æ–π –≤ –≤–∞—Ä–∏–∞–Ω—Ç–µ, –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å–æ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é —ç—Ç–∞–ø–æ–≤.
1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–∫–µ—Ç—ã –∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏.
2. –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞.
3. –í—ã–ø–æ–ª–Ω–∏—Ç—å —Ä–∞–∑–≤–µ–¥–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —ç—Ç–∞–ø–∞–º–∏ –æ–ø–∏—Å–∞–Ω–Ω—ã–º–∏ –≤ —Ñ–∞–π–ª–µ –≠—Ç–∞–ø—ã –ø—Ä–æ–µ–∫—Ç–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤ –ø—Ä–∏–º–µ—Ä–∞—Ö.pdf:\
a. –û–∑–Ω–∞–∫–æ–º–ª–µ–Ω–∏–µ —Å –¥–∞–Ω–Ω—ã–º–∏ —Å –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–æ–≤ –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏;\
b. –í—ã–ø–æ–ª–Ω–∏—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö –æ–¥–Ω–æ–º–µ—Ä–Ω—É—é –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏ –º–Ω–æ–≥–æ–º–µ—Ä–Ω—É—é –¥–ª—è –≤—ã—è—Å–Ω–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏;\
c. –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ—á–∏—Å—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö –æ–¥–Ω–∏–º –∏–∑ –º–µ—Ç–æ–¥–æ–≤.\
d. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—É—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏;\
e. –ü–æ—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å –∫–æ–º–±–∏–Ω–∞—Ü–∏—è–º–∏ –∞—Ç—Ä–∏–±—É—Ç–æ–≤. –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã –≤ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö.\
f. –í—ã–ø–æ–ª–Ω–∏—Ç—å –æ—Ç–±–æ—Ä —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\
g. –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –æ–¥–Ω–∏–º –∏–∑ –º–µ—Ç–æ–¥–æ–≤.\
h. –í—ã–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±–æ–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ (–∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ) –æ–¥–Ω–∏–º –∏–∑ –º–µ—Ç–æ–¥–æ–≤ –ø–æ –≤–∞—Ä–∏–∞–Ω—Ç—É.
4. –ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –¥–ª—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö, –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö. –í–æ –≤—Å–µ—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö –≤—ã–¥–µ–ª–∏—Ç—å –æ–±—É—á–∞—é—â—É—é, –ø—Ä–æ–≤–µ—Ä–æ—á–Ω—É—é (–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é) –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
5. –°—Ä–∞–≤–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –º–æ–¥–µ–ª–∏, —É–∫–∞–∑–∞–Ω–Ω–æ–π –≤ –≤–∞—Ä–∏–∞–Ω—Ç–µ, –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∞—Ö –¥–ª—è –≤—Å–µ—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö, –≤–∫–ª—é—á–∞—è –∏—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã. –î–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏: –∫–æ—Ä–µ–Ω—å –∏–∑ —Å—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–π –æ—à–∏–±–∫–∏, –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏ R2.
6. –î–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –ª—É—á—à–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ.
7. –î–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –ª—É—á—à–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –≤—ã–ø–æ–ª–Ω–∏—Ç—å Grid –ø–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∞—Ö. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –ª—É—á—à–∏—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
8. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–ª—É—á–µ–Ω–Ω–æ–π –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ Grid –ø–æ–∏—Å–∫–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ. –°—Ä–∞–≤–Ω–∏—Ç—å –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –ª—É—á—à–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –¥–æ –ø–æ–∏—Å–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –ø–æ—Å–ª–µ –ø–æ–∏—Å–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
9. –°–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã –ø–æ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É.

# –ü–û–°–¢–ê–ù–û–í–ö–ê –ò–ù–î–ò–í–ò–î–£–ê–õ–¨–ù–´–ô –í–ê–†–ò–ê–ù–¢ –ó–ê–î–ê–ù–ò–Ø
–í–∞—Ä–∏–∞–Ω—Ç 13

**–¶–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞:** –ü—Ä–æ–≤–µ—Å—Ç–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Ç–µ–ª–µ–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –±–æ–ª–µ–∑–Ω–∏ –ü–∞—Ä–∫–∏–Ω—Å–æ–Ω–∞ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ü–µ–ª–µ–≤–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ `total_UPDRS` –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π.

## –§–æ—Ä–º–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
**–ü—Ä–æ–±–ª–µ–º–∞:** –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—â–µ–≥–æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è UPDRS (Unified Parkinson's Disease Rating Scale) –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤.

**–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è:** `total_UPDRS`

**–í—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:** –í—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö, –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º:
- `motor_UPDRS` (–∏—Å–∫–ª—é—á–µ–Ω –ø–æ —É—Å–ª–æ–≤–∏—é –≤–∞—Ä–∏–∞–Ω—Ç–∞)
- `index`, `subject#` (—Å–ª—É–∂–µ–±–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã)

**–û—Å–Ω–æ–≤–Ω—ã–µ —ç—Ç–∞–ø—ã —Ä–µ—à–µ–Ω–∏—è:**
1. –†–∞–∑–≤–µ–¥–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (EDA) —Å –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
2. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö, –≤–∫–ª—é—á–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é –∏ –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
3. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö —Ç–∏–ø–æ–≤ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π:
   - –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å(MLP) Multi-Layer Perceptron
   - –î–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è LSTM-—Å–µ—Ç—å
4. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π

## –ú–æ—Ç–∏–≤–∞—Ü–∏—è –∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ
**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å:** –†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –¥–ª—è:
- –ù–µ–∏–Ω–≤–∞–∑–∏–≤–Ω–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∏—Ä–æ–≤–∞–Ω–∏—è –±–æ–ª–µ–∑–Ω–∏ –ü–∞—Ä–∫–∏–Ω—Å–æ–Ω–∞
- –û–±—ä–µ–∫—Ç–∏–≤–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ª–µ—á–µ–Ω–∏—è
- –†–∞–Ω–Ω–µ–≥–æ –≤—ã—è–≤–ª–µ–Ω–∏—è —É—Ö—É–¥—à–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤

**–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:**
- RMSE (–∫–æ—Ä–µ–Ω—å –∏–∑ —Å—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–π –æ—à–∏–±–∫–∏)
- R¬≤ (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏)

## –ü—Ä–µ–¥–º–µ—Ç–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
–ë–æ–ª–µ–∑–Ω—å –ü–∞—Ä–∫–∏–Ω—Å–æ–Ω–∞ - –ø—Ä–æ–≥—Ä–µ—Å—Å–∏—Ä—É—é—â–µ–µ –Ω–µ–≤—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–µ, –≥–¥–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å UPDRS —è–≤–ª—è–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–º –æ—Ü–µ–Ω–∫–∏ —Ç—è–∂–µ—Å—Ç–∏ —Å–∏–º–ø—Ç–æ–º–æ–≤. –ì–æ–ª–æ—Å–æ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (jitter, shimmer, HNR –∏ –¥—Ä.) —è–≤–ª—è—é—Ç—Å—è –≤–∞–∂–Ω—ã–º–∏ –º–∞—Ä–∫–µ—Ä–∞–º–∏ –¥–≤–∏–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –Ω–∞—Ä—É—à–µ–Ω–∏–π, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω—ã–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞—Ü–∏–µ–Ω—Ç–∞.

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import random
from pandas.plotting import scatter_matrix
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import KNNImputer
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import tensorflow as tf
#from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization, LSTM, Bidirectional, Masking
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from scipy.stats import loguniform, randint
from scipy.stats.mstats import winsorize
from sklearn.base import BaseEstimator, TransformerMixin
from scipy.stats import skew, kurtosis
from IPython.display import display
import warnings
warnings.filterwarnings('ignore')
# We will ensure the reproducibility of calculations by fixing the random seed values, enabling deterministic operations in TensorFlow, and limiting multithreading.
SEED = 42
os.environ["PYTHONHASHSEED"] = str(SEED)
os.environ["TF_DETERMINISTIC_OPS"] = "1"
os.environ["TF_CUDNN_DETERMINISTIC"] = "1"
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["TF_NUM_INTRAOP_THREADS"] = "1"
os.environ["TF_NUM_INTEROP_THREADS"] = "1"

random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# Load the dataset
data_path = 'E:/Data-mining-based-on-machine-learning-methods/lab1/LR!_datasets/V5.csv'
df = pd.read_csv(data_path)

print(f"–†–∞–∑–º–µ—Ä: {df.shape}")
print(f"–ö–æ–ª–æ–Ω–∫–∏: {df.columns.tolist()}")

print("\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:")
display(df.head())
size_mb = os.path.getsize(data_path) / (1024 * 1024)

print("=== –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö ===")
print(f"1Ô∏è‚É£ –†–∞–∑–º–µ—Ä –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {size_mb:.2f} –ú–ë")
print(f"2Ô∏è‚É£ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
print(f"3Ô∏è‚É£ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df.columns)}")
print(f"4Ô∏è‚É£ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: 'total_UPDRS' (—Ç–∏–ø: {df['total_UPDRS'].dtype})")
print(f"5Ô∏è‚É£ –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫: 'sex' (–±–∏–Ω–∞—Ä–Ω—ã–π 0/1)")
print(f"6Ô∏è‚É£ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤: {df['subject#'].nunique()}")
print(f"7Ô∏è‚É£ –í—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω —Ç–µ—Å—Ç–æ–≤: {df['test_time'].min()} ‚Üí {df['test_time'].max()}")
df.info()
print("\n=== –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–ø–æ –∫–æ–ª–æ–Ω–∫–∞–º) ===")
missing_cols = df.isnull().sum()
missing_cols = missing_cols[missing_cols > 0]   # —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –≥–¥–µ –µ—Å—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏
print(missing_cols)

print("\n=== –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–ø–æ —Å—Ç—Ä–æ–∫–∞–º) ===")
missing_rows = df.isnull().sum(axis=1)
missing_rows = missing_rows[missing_rows > 0]   # —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏
print(missing_rows)

#### –ù–∞—à –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –æ–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç 24 –ø—Ä–∏–∑–Ω–∞–∫–∞, –ø—Ä–∏ —ç—Ç–æ–º —É –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ ‚Äî Jitter(Abs) ‚Äî –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∑–Ω–∞—á–µ–Ω–∏—è –≤ 2931 –∑–∞–ø–∏—Å–∏ –∏–∑ –æ–±—â–µ–≥–æ —á–∏—Å–ª–∞ 5875. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –æ—Ç—Ä–∞–∂–µ–Ω—ã –≤ —Ä–∞–∑–¥–µ–ª–µ –ø–æ–∏—Å–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –ø–æ —Å—Ç—Ä–æ–∫–∞–º. –ù–∞—à –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –≤–∫–ª—é—á–∞–µ—Ç 19 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ç–∏–ø–∞ float –∏ 5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ç–∏–ø–∞ integer, —Å—Ä–µ–¥–∏ –∫–æ—Ç–æ—Ä—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è sex —è–≤–ª—è–µ—Ç—Å—è –±–∏–Ω–∞—Ä–Ω—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º (0 –∏–ª–∏ 1).
**Unnamed: 0, index –∏ subject# (—Å–ª—É–∂–µ–±–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã, –Ω–µ –Ω–µ—Å—É—â–∏–µ —Å–º—ã—Å–ª–æ–≤–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏)**

print("=== –û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö ===")
display(df.describe(include="all"))

##  –°–≤–æ–¥–∫–∞ –ø–æ –Ω–∞–±–æ—Ä—É –¥–∞–Ω–Ω—ã—Ö
- **–†–∞–∑–º–µ—Ä –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö**: 5875 –∑–∞–ø–∏—Å–µ–π, 24 –ø—Ä–∏–∑–Ω–∞–∫–∞.  
- **–ü–∞—Ü–∏–µ–Ω—Ç—ã**: 42 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ü–∏–µ–Ω—Ç–∞ (`subject#` –æ—Ç 1 –¥–æ 42).  
- **–í–æ–∑—Ä–∞—Å—Ç**: 36‚Äì85 –ª–µ—Ç, —Å—Ä–µ–¥–Ω–µ–µ ‚âà 65 –ª–µ—Ç.  
- **–ü–æ–ª**: –±–∏–Ω–∞—Ä–Ω—ã–π (0 = –º—É–∂—á–∏–Ω–∞, 1 = –∂–µ–Ω—â–∏–Ω–∞), –æ–∫–æ–ª–æ 32% –∂–µ–Ω—â–∏–Ω.  
- **–í—Ä–µ–º—è —Ç–µ—Å—Ç–∞**: ‚Äì4.26 ‚Üí 215.49 (–≤–µ—Ä–æ—è—Ç–Ω–æ, –¥–Ω–∏/—á–∞—Å—ã, –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ).  

###  –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
- `motor_UPDRS`: 5.03 ‚Äì 39.51 (—Å—Ä–µ–¥–Ω–µ–µ ‚âà 21.3).  
  ‚ö†Ô∏è –ë—É–¥–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∞ (–æ—Å—Ç–∞–≤–ª—è–µ–º –æ–¥–Ω—É —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é).  
- `total_UPDRS`: 7.0 ‚Äì 54.99 (—Å—Ä–µ–¥–Ω–µ–µ ‚âà 29.0).  

### üéô –ì–æ–ª–æ—Å–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
- **Jitter, Shimmer, NHR, HNR, RPDE, DFA, PPE**: –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –º–∞–ª—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–¥–æ–ª–∏).  
- –ï—Å—Ç—å –≤—ã–±—Ä–æ—Å—ã: `Jitter` –¥–æ 0.0999, `Shimmer(dB)` –¥–æ 2.107.  
- **Jitter(Abs)**: –∏–º–µ–µ—Ç –ø—Ä–æ–ø—É—Å–∫–∏ (—Ç–æ–ª—å–∫–æ 2944 –∏–∑ 5875 –∑–∞–ø–æ–ª–Ω–µ–Ω—ã).  

### üìå –ö–ª—é—á–µ–≤–æ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ
–ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Ö–æ—Ä–æ—à–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏.  
–¢—Ä–µ–±—É–µ—Ç—Å—è –æ—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –∫ –ø—Ä–æ–ø—É—Å–∫–∞–º –≤ **Jitter(Abs)**  
–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ **test_time** (–º–∞—Å—à—Ç–∞–±/–µ–¥–∏–Ω–∏—Ü—ã).

# === –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–Ω—É–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===
cols_to_drop = ['motor_UPDRS', 'Unnamed: 0', 'index']
existing_cols = [col for col in cols_to_drop if col in df.columns]

if existing_cols:  # –µ—Å–ª–∏ —Ç–∞–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Ä–µ–∞–ª—å–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
    df = df.drop(columns=existing_cols)
    print(f"\n‚úÖ –£–¥–∞–ª–µ–Ω—ã –Ω–µ–Ω—É–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {existing_cols}")
else:
    print("\n‚ÑπÔ∏è –ù–µ–Ω—É–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")

# === –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞—Ü–∏–µ–Ω—Ç–∞–º —Å –ª–∏–Ω–∏–µ–π —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è ===
subject_counts = df['subject#'].value_counts()
mean_count = subject_counts.mean()
min_count = subject_counts.min()
max_count = subject_counts.max()

plt.figure(figsize=(10,6))

# Histogram
n, bins, patches = plt.hist(subject_counts, bins=30, color="steelblue", edgecolor="black", alpha=0.7, density=True)

# Overlay KDE line to show distribution type
import seaborn as sns
sns.kdeplot(subject_counts, color="darkred", linewidth=2)

# Add vertical lines for min, mean, max
plt.axvline(mean_count, color='green', linestyle='--', linewidth=2, label=f"–°—Ä–µ–¥–Ω–µ–µ: {mean_count:.2f}")
plt.axvline(min_count, color='orange', linestyle=':', linewidth=2, label=f"–ú–∏–Ω: {min_count}")
plt.axvline(max_count, color='purple', linestyle=':', linewidth=2, label=f"–ú–∞–∫—Å: {max_count}")

plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏–∑–º–µ—Ä–µ–Ω–∏–π –ø–æ –ø–∞—Ü–∏–µ–Ω—Ç–∞–º —Å –ª–∏–Ω–∏–µ–π –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏", fontsize=14)
plt.xlabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–º–µ—Ä–µ–Ω–∏–π")
plt.ylabel("–ü–ª–æ—Ç–Ω–æ—Å—Ç—å")
plt.legend()

# Add text annotation below the histogram showing average range
plt.figtext(0.15, -0.05, f"–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–º–µ—Ä–µ–Ω–∏–π: {mean_count:.2f} | –ú–∏–Ω: {min_count}, –ú–∞–∫—Å: {max_count}", fontsize=10)

plt.show()

# === –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥ total_UPDRS –ø–æ –≤—Ä–µ–º–µ–Ω–∏ ===
# Tells you whether time is a strong predictor
plt.figure(figsize=(10,6))
df_grouped = df.groupby("test_time")["total_UPDRS"].mean()
plt.plot(df_grouped.index, df_grouped.values, color="darkred")
plt.title("–ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥ total_UPDRS –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", fontsize=14)
plt.xlabel("–í—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
plt.ylabel("–°—Ä–µ–¥–Ω–µ–µ total_UPDRS")
plt.grid(True)
plt.show()

print("")

–°–ª–∞–±—ã–π –ø—Ä–æ–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–∑–Ω–∞–∫: –°–∞–º –ø–æ —Å–µ–±–µ test_time (–≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è), —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –±—É–¥–µ—Ç —Å–ª–∞–±—ã–º –ø—Ä–∏–∑–Ω–∞–∫–æ–º –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è total_UPDRS –≤ –º–æ–¥–µ–ª–∏. –ú–æ–¥–µ–ª—å –Ω–µ –º–æ–∂–µ—Ç –≤—ã—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—É—é –≤–∑–∞–∏–º–æ—Å–≤—è–∑—å –∏–∑ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö.

–ì—Ä–∞—Ñ–∏–∫ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω—É—é, –Ω–æ –∏–∑–º–µ–Ω—á–∏–≤—É—é —Å—Ä–µ–¥–Ω—é—é —Ç—è–∂–µ—Å—Ç—å —Å–∏–º–ø—Ç–æ–º–æ–≤ —Å —Ç–µ—á–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏, —á—Ç–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –∏—Å–∫–∞—Ç—å —Ö–æ—Ä–æ—à–∏–µ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä—ã –æ—Ü–µ–Ω–æ–∫ UPDRS –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ –ø—Ä–æ—Å—Ç–æ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–∫—Ç–æ—Ä–∞.
# === –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π ===
# Features highly correlated with total_UPDRS are potential predictors.
# Features highly correlated with each other may be redundant.
# Helps with feature selection and avoiding multicollinearity.
corr_matrix = df.corr()
plt.figure(figsize=(10, 10))
sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0)
plt.title('–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=16)
plt.tight_layout()
plt.show()

target_corr = corr_matrix['total_UPDRS'].sort_values(ascending=False)
print("\n=== –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å total_UPDRS ===")
print(target_corr)
# === –°–∏–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—â–∏–µ –ø–∞—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏) ===
high_corr_records = []

for i, col1 in enumerate(corr_matrix.columns):
    for j, col2 in enumerate(corr_matrix.columns):
        if i < j:  # –∏–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ —Å–∞–º–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            corr_val = corr_matrix.loc[col1, col2]
            comment = (
                "‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω–∞—è –∏–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç—å (|–∫–æ—Ä—Ä| > 0.9)"
                if abs(corr_val) > 0.9
                else "–ü—Ä–æ–±–ª–µ–º –∏–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–µ—Ç"
            )
            high_corr_records.append((col1, col2, corr_val, comment))
            
# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ DataFrame –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
high_corr_df = pd.DataFrame(
    high_corr_records,
    columns=["–ü—Ä–∏–∑–Ω–∞–∫ 1", "–ü—Ä–∏–∑–Ω–∞–∫ 2", "–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è", "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]
).sort_values(by="–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è", key=lambda x: abs(x), ascending=False)

print("\n=== –¢–∞–±–ª–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –ø–∞—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===")
display(high_corr_df.head(20))  # –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-20 —Å–∞–º—ã—Ö —Å–∏–ª—å–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π

# Create combined features on a copy of the dataset
shimmer_features = ['Shimmer', 'Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5', 'Shimmer:APQ11', 'Shimmer:DDA']
jitter_features = ['Jitter(%)', 'Jitter(Abs)', 'Jitter:RAP', 'Jitter:PPQ5', 'Jitter:DDP']

# Create a copy for analysis
df_analysis = df.copy()

# Create combined features on the copy
df_analysis['jitter_combined'] = df_analysis[jitter_features].mean(axis=1)
df_analysis['shimmer_combined'] = df_analysis[shimmer_features].mean(axis=1)

# Perform correlation on the analysis dataset
correlation = df_analysis.corr()
plt.figure(figsize=(12, 10))
plt.title("Correlation Matrix (Including Combined Features)")
sns.heatmap(correlation, vmax=1, square=True, annot=False, cmap="YlGnBu")
plt.tight_layout()
plt.show()

# –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ –∏ –¥—Ä—É–≥–∏–µ –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
features_to_keep = [
    'subject#', 'age', 'sex', 'test_time', 'total_UPDRS',
    'shimmer_combined', 'jitter_combined',
    'NHR', 'HNR', 'RPDE', 'DFA', 'PPE'
]

df_combined = df_analysis[features_to_keep]

# –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é –Ω–∞ –Ω–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö
correlation = df_combined.corr()
plt.figure(figsize=(10, 10))
plt.title("–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")
sns.heatmap(correlation, vmax=1, square=True, annot=True, cmap="YlGnBu", fmt='.2f')
plt.tight_layout()
plt.show()

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ—Ç–¥–µ–ª—å–Ω–æ
print("\n=== –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å total_UPDRS (–ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤) ===")
target_corr_new = correlation['total_UPDRS'].sort_values(ascending=False)
print(target_corr_new)


# –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å—Ç–∞–≤—à—É—é—Å—è –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å
print("\n=== –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å ===")
# –ò—â–µ–º –≤—ã—Å–æ–∫–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞–º–∏ (–∏—Å–∫–ª—é—á–∞—è —Ü–µ–ª–µ–≤—É—é –∏ subject#)
predictor_corr = correlation.drop(['total_UPDRS', 'subject#'], errors='ignore')
predictor_corr = predictor_corr.drop(['total_UPDRS', 'subject#'], axis=1, errors='ignore')

# –ù–∞—Ö–æ–¥–∏–º –≤—ã—Å–æ–∫–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞–º–∏ (–∞–±—Å–æ–ª—é—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ > 0.7)
high_corr_pairs = []
for i in range(len(predictor_corr.columns)):
    for j in range(i+1, len(predictor_corr.columns)):
        if abs(predictor_corr.iloc[i, j]) > 0.7:
            high_corr_pairs.append((
                predictor_corr.columns[i],
                predictor_corr.columns[j],
                predictor_corr.iloc[i, j]
            ))

if high_corr_pairs:
    print("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤—ã—Å–æ–∫–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å):")
    for feature1, feature2, corr_value in high_corr_pairs:
        print(f"  {feature1} - {feature2}: {corr_value:.3f}")
else:
    print("–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–π –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ (–≤—Å–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ < |0.7|)")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–ª—É –Ω–∞—à–∏—Ö –Ω–æ–≤—ã—Ö –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
print(f"\n–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π:")
print(f"shimmer_combined: {correlation.loc['shimmer_combined', 'total_UPDRS']:.3f}")
print(f"jitter_combined: {correlation.loc['jitter_combined', 'total_UPDRS']:.3f}")

**–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ:**

–í –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è **–º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å** –º–µ–∂–¥—É –∞–∫—É—Å—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (shimmer_combined, jitter_combined, NHR, HNR), –Ω–æ –º—ã —Ä–µ—à–∏–º —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É —Å –ø–æ–º–æ—â—å—é **winsorizing** –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã–±—Ä–æ—Å–æ–≤, —á—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ –ø—Ä–∏ —É–º–µ–Ω—å—à–µ–Ω–Ω–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.

–ß—Ç–æ –∫–∞—Å–∞–µ—Ç—Å—è **–Ω–∏–∑–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏** shimmer_combined –∏ jitter_combined —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ. –•–æ—Ç—è —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–∞—é—Ç —Å–ª–∞–±—É—é –ª–∏–Ω–µ–π–Ω—É—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å, –≤ **LSTM –∏ MLP –º–æ–¥–µ–ª—è—Ö** —ç—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–≥—É—Ç –∏–≥—Ä–∞—Ç—å crucial —Ä–æ–ª—å –±–ª–∞–≥–æ–¥–∞—Ä—è:

- **–ù–µlinear interactions**, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –≤–∏–¥–Ω—ã –≤ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ
- **–í—Ä–µ–º–µ–Ω–Ω—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º**, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞—Å–∫—Ä—ã–≤–∞—é—Ç—Å—è –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è—Ö
- **–ö–æ–º–±–∏–Ω–∞—Ç–æ—Ä–Ω—ã–º —ç—Ñ—Ñ–µ–∫—Ç–∞–º** —Å –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π

**–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º:** –¢–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ - –ª–∏—à—å –æ—Ç–ø—Ä–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞, –∞ –Ω–∞—Å—Ç–æ—è—â–∞—è —Å–∏–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–æ—è–≤–∏—Ç—Å—è –≤ —Å–ª–æ–∂–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö, —É—á–∏—Ç—ã–≤–∞—é—â–∏—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.

# === –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –∏ –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏ ===
numeric_features = df_combined.select_dtypes(include=[np.number]).columns
skew_kurt = pd.DataFrame({
    "–ê—Å–∏–º–º–µ—Ç—Ä–∏—è": df_combined[numeric_features].apply(lambda x: skew(x.dropna())),
    "–≠–∫—Å—Ü–µ—Å—Å": df_combined[numeric_features].apply(lambda x: kurtosis(x.dropna()))
})

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
def get_skewness_recommendation(skew_val, kurt_val):
    recommendations = []
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏
    if skew_val > 1:
        recommendations.append("–ù—É–∂–Ω–æ —É–±—Ä–∞—Ç—å –∫—Ä–∞–π–Ω–µ –≤—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è")
    elif skew_val > 0.5:
        recommendations.append("–í–æ–∑–º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å –≤—ã—Å–æ–∫–∏–µ –≤—ã–±—Ä–æ—Å—ã")
    elif skew_val < -1:
        recommendations.append("–ù—É–∂–Ω–æ —É–±—Ä–∞—Ç—å –∫—Ä–∞–π–Ω–µ –Ω–∏–∑–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è")
    elif skew_val < -0.5:
        recommendations.append("–í–æ–∑–º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å –Ω–∏–∑–∫–∏–µ –≤—ã–±—Ä–æ—Å—ã")
    else:
        recommendations.append("–ê—Å–∏–º–º–µ—Ç—Ä–∏—è –≤ –Ω–æ—Ä–º–µ")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —ç–∫—Å—Ü–µ—Å—Å—É
    if kurt_val > 2:
        recommendations.append("–ú–Ω–æ–≥–æ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—ã–±—Ä–æ—Å—ã")
    elif kurt_val > 1:
        recommendations.append("–í–æ–∑–º–æ–∂–Ω—ã –≤—ã–±—Ä–æ—Å—ã –ø–æ –∫—Ä–∞—è–º")
    elif kurt_val < -1:
        recommendations.append("–†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ - —Ö–æ—Ä–æ—à–æ")
    else:
        recommendations.append("–≠–∫—Å—Ü–µ—Å—Å –≤ –Ω–æ—Ä–º–µ")
    
    return "\n".join(recommendations)

skew_kurt["–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"] = skew_kurt.apply(
    lambda row: get_skewness_recommendation(row["–ê—Å–∏–º–º–µ—Ç—Ä–∏—è"], row["–≠–∫—Å—Ü–µ—Å—Å"]), 
    axis=1
)

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –ø–æ–∫–∞–∑–∞ —Ç–µ–∫—Å—Ç–∞
pd.set_option('display.max_colwidth', None)
pd.set_option('display.width', None)



# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ
plt.figure(figsize=(12, 6))
bars = plt.bar(skew_kurt.index, skew_kurt['–ê—Å–∏–º–º–µ—Ç—Ä–∏—è'], color='skyblue', edgecolor='navy', alpha=0.7)

# –î–æ–±–∞–≤–ª—è–µ–º —Ü–≤–µ—Ç–æ–≤—É—é –∏–Ω–¥–∏–∫–∞—Ü–∏—é –¥–ª—è –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏
for bar, skew_val in zip(bars, skew_kurt['–ê—Å–∏–º–º–µ—Ç—Ä–∏—è']):
    if abs(skew_val) > 1:  # –°–∏–ª—å–Ω–∞—è –∞—Å–∏–º–º–µ—Ç—Ä–∏—è
        bar.set_color('red')
    elif abs(skew_val) > 0.5:  # –£–º–µ—Ä–µ–Ω–Ω–∞—è –∞—Å–∏–º–º–µ—Ç—Ä–∏—è
        bar.set_color('orange')
    else:  # –°–ª–∞–±–∞—è –∞—Å–∏–º–º–µ—Ç—Ä–∏—è
        bar.set_color('green')

plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)
plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='–£–º–µ—Ä–µ–Ω–Ω–∞—è –∞—Å–∏–º–º–µ—Ç—Ä–∏—è')
plt.axhline(y=-0.5, color='gray', linestyle='--', alpha=0.5)
plt.axhline(y=1, color='red', linestyle='--', alpha=0.5, label='–°–∏–ª—å–Ω–∞—è –∞—Å–∏–º–º–µ—Ç—Ä–∏—è')
plt.axhline(y=-1, color='red', linestyle='--', alpha=0.5)

plt.title('–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=14, fontweight='bold')
plt.xlabel('–ü—Ä–∏–∑–Ω–∞–∫–∏')
plt.ylabel('–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏')
plt.xticks(rotation=45, ha='right')
plt.legend()
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()

print("\n=== –ê—Å–∏–º–º–µ—Ç—Ä–∏—è –∏ —ç–∫—Å—Ü–µ—Å—Å (—á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏) ===")

display(skew_kurt)

# –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã —Å –ª–∏–Ω–∏—è–º–∏ –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏
n_cols = 4
n_rows = (len(numeric_features) + n_cols - 1) // n_cols

fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 4*n_rows))
axes = axes.flatten()

for i, col in enumerate(numeric_features):
    if i < len(axes):
        # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞
        axes[i].hist(df_combined[col].dropna(), bins=30, alpha=0.7, color='skyblue', edgecolor='black', density=True)
        
        # –õ–∏–Ω–∏—è —Å—Ä–µ–¥–Ω–µ–≥–æ
        mean_val = df_combined[col].mean()
        axes[i].axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'–°—Ä–µ–¥–Ω–µ–µ: {mean_val:.2f}')
        
        # –õ–∏–Ω–∏—è –º–µ–¥–∏–∞–Ω—ã
        median_val = df_combined[col].median()
        axes[i].axvline(median_val, color='green', linestyle='--', linewidth=2, label=f'–ú–µ–¥–∏–∞–Ω–∞: {median_val:.2f}')
        
        # KDE
        df_combined[col].dropna().plot.density(ax=axes[i], color='darkblue', linewidth=2)
        
        skew_val = skew_kurt.loc[col, '–ê—Å–∏–º–º–µ—Ç—Ä–∏—è']
        axes[i].set_title(f'{col}\n–ê—Å–∏–º–º–µ—Ç—Ä–∏—è: {skew_val:.2f}', fontsize=10)
        axes[i].legend(fontsize=8)
        
        # –¶–≤–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏
        if abs(skew_val) > 1:
            axes[i].title.set_color('red')
        elif abs(skew_val) > 0.5:
            axes[i].title.set_color('orange')

# –°–∫—Ä—ã–≤–∞–µ–º –ø—É—Å—Ç—ã–µ subplots
for j in range(len(numeric_features), len(axes)):
    axes[j].set_visible(False)

plt.suptitle("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏", fontsize=16, fontweight='bold')
plt.tight_layout()
plt.show()

# –Ø–¥–µ—Ä–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
key_features = ['total_UPDRS', 'shimmer_combined', 'jitter_combined', 'HNR', 'NHR', 'age']
plt.figure(figsize=(14, 8))
for col in key_features:
    if col in df_combined.columns:
        sns.kdeplot(df_combined[col].dropna(), label=f'{col} (–∞—Å–∏–º–º–µ—Ç—Ä–∏—è: {skew_kurt.loc[col, "–ê—Å–∏–º–º–µ—Ç—Ä–∏—è"]:.2f})')
plt.title("–Ø–¥–µ—Ä–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", fontsize=14, fontweight='bold')
plt.xlabel("–ó–Ω–∞—á–µ–Ω–∏—è")
plt.ylabel("–ü–ª–æ—Ç–Ω–æ—Å—Ç—å")
plt.legend()
plt.grid(alpha=0.3)
plt.show()

# –°–≤–æ–¥–∫–∞ –ø–æ –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏
print("\n=== –°–≤–æ–¥–∫–∞ –ø–æ –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏ ===")
strong_skew = skew_kurt[abs(skew_kurt['–ê—Å–∏–º–º–µ—Ç—Ä–∏—è']) > 1]
moderate_skew = skew_kurt[(abs(skew_kurt['–ê—Å–∏–º–º–µ—Ç—Ä–∏—è']) > 0.5) & (abs(skew_kurt['–ê—Å–∏–º–º–µ—Ç—Ä–∏—è']) <= 1)]

if not strong_skew.empty:
    print("–ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –°–ò–õ–¨–ù–û–ô –∞—Å–∏–º–º–µ—Ç—Ä–∏–µ–π (> |1|):")
    print(strong_skew['–ê—Å–∏–º–º–µ—Ç—Ä–∏—è'])
    
if not moderate_skew.empty:
    print("\n–ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –£–ú–ï–†–ï–ù–ù–û–ô –∞—Å–∏–º–º–µ—Ç—Ä–∏–µ–π (0.5 < |x| ‚â§ 1):")
    print(moderate_skew['–ê—Å–∏–º–º–µ—Ç—Ä–∏—è'])

normal_skew = skew_kurt[abs(skew_kurt['–ê—Å–∏–º–º–µ—Ç—Ä–∏—è']) <= 0.5]
if not normal_skew.empty:
    print(f"\n–ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º (–∞—Å–∏–º–º–µ—Ç—Ä–∏—è ‚â§ |0.5|): {len(normal_skew)}")



# === –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ –º–µ—Ç–æ–¥–æ–º IQR ===
print("\n=== –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ (–º–µ—Ç–æ–¥ IQR) ===")
outlier_summary = []

features_to_check = [
    'subject#', 'age', 'sex', 'test_time', 'total_UPDRS',
    'shimmer_combined', 'jitter_combined', 'NHR', 'HNR', 'RPDE', 'DFA', 'PPE'
]

for col in features_to_check:
    Q1 = df_combined[col].quantile(0.25)
    Q3 = df_combined[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    n_outliers = ((df_combined[col] < lower) | (df_combined[col] > upper)).sum()
    total_rows = len(df_combined)
    outlier_percentage = (n_outliers / total_rows) * 100
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –ø—Ä–æ–±–ª–µ–º—ã
    if outlier_percentage > 20:
        status = "üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –£–†–û–í–ï–ù–¨"
        recommendation = "–¢—Ä–µ–±—É–µ—Ç—Å—è winsorizing/—É–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤"
    elif outlier_percentage > 10:
        status = "‚ö†Ô∏è –í–´–°–û–ö–ò–ô –£–†–û–í–ï–ù–¨"
        recommendation = "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤"
    elif outlier_percentage > 5:
        status = "üî∂ –£–ú–ï–†–ï–ù–ù–´–ô –£–†–û–í–ï–ù–¨"
        recommendation = "–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –≤—ã–±—Ä–æ—Å–æ–≤"
    else:
        status = "‚úÖ –ù–û–†–ú–ê"
        recommendation = "–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è"
    
    outlier_summary.append({
        '–ü—Ä–∏–∑–Ω–∞–∫': col,
        '–ö–æ–ª-–≤–æ –≤—ã–±—Ä–æ—Å–æ–≤': n_outliers,
        '% –≤—ã–±—Ä–æ—Å–æ–≤': f"{outlier_percentage:.1f}%",
        '–°—Ç–∞—Ç—É—Å': status,
        '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è': recommendation,
        '–ì—Ä–∞–Ω–∏—Ü—ã IQR': f"[{lower:.2f}, {upper:.2f}]"
    })

outlier_df = pd.DataFrame(outlier_summary)
display(outlier_df.sort_values("–ö–æ–ª-–≤–æ –≤—ã–±—Ä–æ—Å–æ–≤", ascending=False))

# –ë–æ–∫—Å–ø–ª–æ—Ç—ã –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ df_combined
plt.figure(figsize=(14, 8))
features_for_boxplot = ['total_UPDRS', 'jitter_combined', 'shimmer_combined', 'HNR']
for i, col in enumerate(features_for_boxplot):
    plt.subplot(2, 2, i+1)
    sns.boxplot(x=df_combined[col], color="skyblue")
    plt.title(f"–ë–æ–∫—Å–ø–ª–æ—Ç {col}")
plt.tight_layout()
plt.show()


### total_UPDRS ‚úÖ
–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ, –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ - –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è —Ö–æ—Ä–æ—à–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∞

### jitter_combined üö®
–°–∏–ª—å–Ω–æ —Å–º–µ—â–µ–Ω–æ –≤–ø—Ä–∞–≤–æ -–û–ß–ï–ù–¨ –ú–ù–û–ì–û - –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –Ω–∞—à IQR –∞–Ω–∞–ª–∏–∑ (419 –≤—ã–±—Ä–æ—Å–æ–≤). 
–ü—Ä–æ–±–ª–µ–º–∞: –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –∑–Ω–∞—á–µ–Ω–∏–π —Å–∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–æ –≤–Ω–∏–∑—É, –Ω–æ –µ—Å—Ç—å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –≤—ã–±—Ä–æ—Å—ã. 
–ó–∞–∫–ª—é—á–µ–Ω–∏–µ: –¢—Ä–µ–±—É–µ—Ç—Å—è —Å—Ä–æ—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ winsorizing

### shimmer_combined üö®
–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ jitter - —Å–∏–ª—å–Ω–æ —Å–º–µ—â–µ–Ω–æ –≤–ø—Ä–∞–≤–æ -–ú–ù–û–ì–û - –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç 327 –≤—ã–±—Ä–æ—Å–æ–≤ –∏–∑ IQR
–ü—Ä–æ–±–ª–µ–º–∞: –¢–∞ –∂–µ –∫–∞—Ä—Ç–∏–Ω–∞ - –∫–æ–º–ø–∞–∫—Ç–Ω–æ–µ —è–¥—Ä–æ + –¥–ª–∏–Ω–Ω—ã–π —Ö–≤–æ—Å—Ç –≤—ã–±—Ä–æ—Å–æ–≤
–ó–∞–∫–ª—é—á–µ–Ω–∏–µ: –ù–µ–æ–±—Ö–æ–¥–∏–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ winsorizing

### HNR ‚ö†Ô∏è
–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: –ë–æ–ª–µ–µ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ, –Ω–æ —Å –≤—ã–±—Ä–æ—Å–∞–º–∏
–í—ã–±—Ä–æ—Å—ã: –£–º–µ—Ä–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ (–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç 171 –≤—ã–±—Ä–æ—Å)
–ú–µ–¥–∏–∞–Ω–∞: ~20-25 –µ–¥–∏–Ω–∏—Ü
–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å: –í—ã–±—Ä–æ—Å—ã –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –≤ –Ω–∏–∂–Ω–µ–π —á–∞—Å—Ç–∏
–ó–∞–∫–ª—é—á–µ–Ω–∏–µ: –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

–ù–ï–û–ë–•–û–î–ò–ú–´–ï –î–ï–ô–°–¢–í–ò–Ø:

1. –°–†–û–ß–ù–û: –ü—Ä–∏–º–µ–Ω–∏—Ç—å winsorizing –∫:
   - jitter_combined (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å)
   - shimmer_combined (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å)

2. –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø: –û–±—Ä–∞–±–æ—Ç–∞—Ç—å HNR

3. –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô: total_UPDRS –≤ –æ—Ç–ª–∏—á–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏

üìå –ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ: –í—ã–±—Ä–æ—Å—ã –≤ jitter –∏ shimmer –º–æ–≥—É—Ç –¥–æ–º–∏–Ω–∏—Ä–æ–≤–∞—Ç—å 
   –≤ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –∏ –∏—Å–∫–∞–∂–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã!
""")
# === –î–∏–∞–≥—Ä–∞–º–º—ã —Ä–∞—Å—Å–µ—è–Ω–∏—è: —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è vs –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ===
top_features = ['age', 'HNR', 'NHR']
plt.figure(figsize=(15, 5))
for i, feat in enumerate(top_features):
    plt.subplot(1, 3, i+1)
    sns.scatterplot(x=df_combined[feat], y=df_combined['total_UPDRS'], alpha=0.5)
    plt.title(f'total_UPDRS vs {feat}')
plt.tight_layout()
plt.show()

# === –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ ===
subject_sample = np.random.choice(df_combined['subject#'].unique(), 4, replace=False)
plt.figure(figsize=(12, 8))
for i, subject in enumerate(subject_sample):
    subject_data = df_combined[df_combined['subject#'] == subject].sort_values('test_time')
    plt.subplot(2, 2, i+1)
    plt.plot(subject_data['test_time'], subject_data['total_UPDRS'], marker='o', linestyle='-')
    plt.title(f'–ü–∞—Ü–∏–µ–Ω—Ç {subject}', fontsize=12)
    plt.xlabel('–í—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è')
    plt.ylabel('total_UPDRS')
plt.tight_layout()
plt.show()

üìà –û–ë–©–ê–Ø –ö–ê–†–¢–ò–ù–ê:
   - –ù–∏ –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–∏–ª—å–Ω–æ–π –ª–∏–Ω–µ–π–Ω–æ–π —Å–≤—è–∑–∏ —Å UPDRS
   - –≠—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å —Å–ª–æ–∂–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (LSTM/MLP)
   - –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–æ–≥—É—Ç –±—ã—Ç—å –≤–∞–∂–Ω–µ–µ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π

print("=" * 80)
print("B. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• - TWO DATASET APPROACH")
print("=" * 80)

# –°–æ–∑–¥–∞–µ–º –¥–≤–µ —Ä–∞–±–æ—á–∏–µ –∫–æ–ø–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏–π
df_full = df.copy()  # For versions 1 & 2
df_reduced = df_combined.copy()  # For versions 3 & 4

print("üìä –ò–°–•–û–î–ù–´–ï –î–ê–¢–ê–°–ï–¢–´:")
print(f"df_full: {df_full.shape}")
print(f"df_reduced: {df_reduced.shape}")

print("\nB.1 –£–î–ê–õ–ï–ù–ò–ï –°–¢–û–õ–ë–¶–û–í")
print("-" * 40)

columns_to_remove = ['motor_UPDRS', 'index', 'subject#', 'Unnamed: 0']

for df_name, dataset in [('df_full', df_full), ('df_reduced', df_reduced)]:
    print(f"\n–û–±—Ä–∞–±–æ—Ç–∫–∞ {df_name}:")
    original_shape = dataset.shape
    for col in columns_to_remove:
        if col in dataset.columns:
            dataset.drop(col, axis=1, inplace=True)
            print(f"  ‚úÖ –£–¥–∞–ª–µ–Ω '{col}'")
    print(f"  –†–∞–∑–º–µ—Ä: {original_shape} ‚Üí {dataset.shape}")

print("\nB.2 –ê–ù–ê–õ–ò–ó F-SCORE (SELECTKBEST)")
print("-" * 40)

def analyze_feature_importance(df, df_name):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é SelectKBest"""
    print(f"\nüìä –ê–ù–ê–õ–ò–ó F-SCORE –î–õ–Ø {df_name}:")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X = df.drop('total_UPDRS', axis=1)
    y = df['total_UPDRS']
    
    # –ö–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    if 'sex' in X.columns and X['sex'].dtype == 'object':
        X['sex'] = X['sex'].astype('category').cat.codes
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ–¥–∏–∞–Ω–æ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    if X.isnull().sum().sum() > 0:
        X_filled = X.fillna(X.median())
    else:
        X_filled = X.copy()
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º SelectKBest
    k_best = SelectKBest(score_func=f_regression, k='all')
    k_best.fit(X_filled, y)
    
    # –°–æ–∑–¥–∞–µ–º DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    feature_importance = pd.DataFrame({
        'Feature': X.columns,
        'F_Score': k_best.scores_,
        'P_Value': k_best.pvalues_
    }).sort_values('F_Score', ascending=False)
    
    return feature_importance

# –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
feature_importance_full = analyze_feature_importance(df_full, 'df_full')
feature_importance_reduced = analyze_feature_importance(df_reduced, 'df_reduced')

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è F-Score –¥–ª—è –æ–±–æ–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# df_full - Top features
top_full = feature_importance_full.head(15)
colors_full = ['red' if pval < 0.05 else 'blue' for pval in top_full['P_Value']]
axes[0, 0].barh(top_full['Feature'], top_full['F_Score'], color=colors_full, alpha=0.7)
axes[0, 0].set_title('df_full -–¢–û–ü 15 –ü–†–ò–ó–ù–ê–ö–û–í –ü–û F-SCORE')
axes[0, 0].set_xlabel('F-Score')
axes[0, 0].invert_yaxis()
axes[0, 0].grid(axis='x', alpha=0.3)

# df_full - –í—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
all_full = feature_importance_full.sort_values('F_Score', ascending=True)
colors_all_full = ['red' if pval < 0.05 else 'blue' for pval in all_full['P_Value']]
axes[0, 1].barh(all_full['Feature'], all_full['F_Score'], color=colors_all_full, alpha=0.7)
axes[0, 1].set_title('df_full - –í–°–ï –ü–†–ò–ó–ù–ê–ö–ò –ü–û F-SCORE')
axes[0, 1].set_xlabel('F-Score')
axes[0, 1].grid(axis='x', alpha=0.3)

# df_reduced - Top features
top_reduced = feature_importance_reduced.head(8)
colors_reduced = ['red' if pval < 0.05 else 'blue' for pval in top_reduced['P_Value']]
axes[1, 0].barh(top_reduced['Feature'], top_reduced['F_Score'], color=colors_reduced, alpha=0.7)
axes[1, 0].set_title('df_reduced - –¢–û–ü 8 –ü–†–ò–ó–ù–ê–ö–û–í –ü–û F-SCORE')
axes[1, 0].set_xlabel('F-Score')
axes[1, 0].invert_yaxis()
axes[1, 0].grid(axis='x', alpha=0.3)

# df_reduced - –í—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
all_reduced = feature_importance_reduced.sort_values('F_Score', ascending=True)
colors_all_reduced = ['red' if pval < 0.05 else 'blue' for pval in all_reduced['P_Value']]
axes[1, 1].barh(all_reduced['Feature'], all_reduced['F_Score'], color=colors_all_reduced, alpha=0.7)
axes[1, 1].set_title('df_reduced - –í–°–ï –ü–†–ò–ó–ù–ê–ö–ò –ü–û F-SCORE')
axes[1, 1].set_xlabel('F-Score')
axes[1, 1].grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.show()

print("\nüìà –ü–û–õ–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ F-SCORE:")
print("=" * 60)

print("\ndf_full - –í–°–ï –ü–†–ò–ó–ù–ê–ö–ò:")
print("-" * 40)
for i, (_, row) in enumerate(feature_importance_full.iterrows(), 1):
    significance = "‚úÖ –∑–Ω–∞—á–∏–º" if row['P_Value'] < 0.05 else "‚ö†Ô∏è –Ω–µ–∑–Ω–∞—á–∏–º"
    print(f"{i:2d}. {row['Feature']:25} F-score = {row['F_Score']:7.1f} p-value = {row['P_Value']:8.4f} ({significance})")

print("\ndf_reduced - –í–°–ï –ü–†–ò–ó–ù–ê–ö–ò:")
print("-" * 40)
for i, (_, row) in enumerate(feature_importance_reduced.iterrows(), 1):
    significance = "‚úÖ –∑–Ω–∞—á–∏–º" if row['P_Value'] < 0.05 else "‚ö†Ô∏è –Ω–µ–∑–Ω–∞—á–∏–º"
    print(f"{i:2d}. {row['Feature']:25} F-score = {row['F_Score']:7.1f} p-value = {row['P_Value']:8.4f} ({significance})")

print("\nB.3 –ê–ù–ê–õ–ò–ó –ü–†–û–ü–£–©–ï–ù–ù–´–• –ó–ù–ê–ß–ï–ù–ò–ô –ò –†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–ò")
print("-" * 40)

def analyze_missing_values(df, df_name, feature_importance):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏ –∏—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å"""
    print(f"\nüîç –ê–ù–ê–õ–ò–ó –ü–†–û–ü–£–©–ï–ù–ù–´–• –ó–ù–ê–ß–ï–ù–ò–ô –î–õ–Ø {df_name}:")
    
    # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    missing_data = df.isnull().sum()
    missing_data = missing_data[missing_data > 0]
    
    if len(missing_data) == 0:
        print("  ‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
        return
    
    print("  –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
    for col, missing_count in missing_data.items():
        missing_percent = (missing_count / len(df)) * 100
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∞
        if col in feature_importance['Feature'].values:
            f_score = feature_importance[feature_importance['Feature'] == col]['F_Score'].values[0]
            p_value = feature_importance[feature_importance['Feature'] == col]['P_Value'].values[0]
            relevance = "‚úÖ –í–´–°–û–ö–ê–Ø" if f_score > 10 else "‚ö†Ô∏è –°–†–ï–î–ù–Ø–Ø" if f_score > 5 else "‚ùå –ù–ò–ó–ö–ê–Ø"
        else:
            f_score = 0
            p_value = 1
            relevance = "‚ùå –ù–ï –û–¶–ï–ù–ï–ù"
        
        print(f"    {col}: {missing_count} –ø—Ä–æ–ø—É—Å–∫–æ–≤ ({missing_percent:.1f}%)")
        print(f"      –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance}, F-score: {f_score:.1f}, p-value: {p_value:.4f}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ
        if missing_percent > 20:
            print(f"      üö® –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –ú–ù–û–ì–û –ü–†–û–ü–£–°–ö–û–í (>20%) - –≤–µ—Ä–æ—è—Ç–Ω–æ MNAR(Missing Not at Random)")
            if relevance == "‚úÖ –í–´–°–û–ö–ê–Ø":
                print(f"      üí° –î–ï–ô–°–¢–í–ò–ï: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—É—é –∏–º–ø—É—Ç–∞—Ü–∏—é (KNN/Regression)")
            else:
                print(f"      üí° –î–ï–ô–°–¢–í–ò–ï: –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —É–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞")
        elif missing_percent > 5:
            print(f"      ‚ö†Ô∏è  –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –£–ú–ï–†–ï–ù–ù–û –ü–†–û–ü–£–°–ö–û–í (5-20%) - –≤–µ—Ä–æ—è—Ç–Ω–æ MAR(Missing at Random)")
            print(f"      üí° –î–ï–ô–°–¢–í–ò–ï: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å KNN –∏–º–ø—É—Ç–∞—Ü–∏—é")
        else:
            print(f"      ‚úÖ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –ú–ê–õ–û –ü–†–û–ü–£–°–ö–û–í (<5%) - –≤–µ—Ä–æ—è—Ç–Ω–æ MCAR(Missing Completely at Random)")
            print(f"      üí° –î–ï–ô–°–¢–í–ò–ï: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç—É—é –∏–º–ø—É—Ç–∞—Ü–∏—é (–º–µ–¥–∏–∞–Ω–∞/—Å—Ä–µ–¥–Ω–µ–µ)")

# –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –æ–±–æ–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
analyze_missing_values(df_full, 'df_full', feature_importance_full)
analyze_missing_values(df_reduced, 'df_reduced', feature_importance_reduced)

print("\nB.3 –ê–ù–ê–õ–ò–ó –ü–†–û–ü–£–©–ï–ù–ù–´–• –ó–ù–ê–ß–ï–ù–ò–ô –ò –†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–ò")
print("-" * 40)

def analyze_missing_values(df, df_name, feature_importance):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏ –∏—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å"""
    print(f"\nüîç –ê–ù–ê–õ–ò–ó –ü–†–û–ü–£–©–ï–ù–ù–´–• –ó–ù–ê–ß–ï–ù–ò–ô –î–õ–Ø {df_name}:")
    
    # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    missing_data = df.isnull().sum()
    missing_data = missing_data[missing_data > 0]
    
    if len(missing_data) == 0:
        print("  ‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
        return
    
    print("  –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
    for col, missing_count in missing_data.items():
        missing_percent = (missing_count / len(df)) * 100
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∞
        if col in feature_importance['Feature'].values:
            f_score = feature_importance[feature_importance['Feature'] == col]['F_Score'].values[0]
            p_value = feature_importance[feature_importance['Feature'] == col]['P_Value'].values[0]
            relevance = "‚úÖ –í–´–°–û–ö–ê–Ø" if f_score > 10 else "‚ö†Ô∏è –°–†–ï–î–ù–Ø–Ø" if f_score > 5 else "‚ùå –ù–ò–ó–ö–ê–Ø"
        else:
            f_score = 0
            p_value = 1
            relevance = "‚ùå –ù–ï –û–¶–ï–ù–ï–ù"
        
        print(f"    {col}: {missing_count} –ø—Ä–æ–ø—É—Å–∫–æ–≤ ({missing_percent:.1f}%)")
        print(f"      –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance}, F-score: {f_score:.1f}, p-value: {p_value:.4f}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ
        if missing_percent > 20:
            print(f"      üö® –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –ú–ù–û–ì–û –ü–†–û–ü–£–°–ö–û–í (>20%) - –≤–µ—Ä–æ—è—Ç–Ω–æ MNAR(Missing Not at Random)")
            if relevance == "‚úÖ –í–´–°–û–ö–ê–Ø":
                print(f"      üí° –î–ï–ô–°–¢–í–ò–ï: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—É—é –∏–º–ø—É—Ç–∞—Ü–∏—é (KNN/Regression)")
            else:
                print(f"      üí° –î–ï–ô–°–¢–í–ò–ï: –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —É–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞")
        elif missing_percent > 5:
            print(f"      ‚ö†Ô∏è  –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –£–ú–ï–†–ï–ù–ù–û –ü–†–û–ü–£–°–ö–û–í (5-20%) - –≤–µ—Ä–æ—è—Ç–Ω–æ MAR(Missing at Random)")
            print(f"      üí° –î–ï–ô–°–¢–í–ò–ï: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å KNN –∏–º–ø—É—Ç–∞—Ü–∏—é")
        else:
            print(f"      ‚úÖ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –ú–ê–õ–û –ü–†–û–ü–£–°–ö–û–í (<5%) - –≤–µ—Ä–æ—è—Ç–Ω–æ MCAR(Missing Completely at Random)")
            print(f"      üí° –î–ï–ô–°–¢–í–ò–ï: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç—É—é –∏–º–ø—É—Ç–∞—Ü–∏—é (–º–µ–¥–∏–∞–Ω–∞/—Å—Ä–µ–¥–Ω–µ–µ)")

# –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –æ–±–æ–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
analyze_missing_values(df_full, 'df_full', feature_importance_full)
analyze_missing_values(df_reduced, 'df_reduced', feature_importance_reduced)

if 'Jitter(Abs)' in df_full.columns:
    df_full = df_full.drop('Jitter(Abs)', axis=1)
    print("‚úÖ Jitter(Abs) —É–¥–∞–ª–µ–Ω –∏–∑ df_full (49.9% –ø—Ä–æ–ø—É—Å–∫–æ–≤)")

print("\nB.4 –û–ë–†–ê–ë–û–¢–ö–ê –í–´–ë–†–û–°–û–í (WINSORIZE)")
print("-" * 40)

def apply_winsorizing(df, df_name):
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç winsorizing –∫ —á–∏—Å–ª–æ–≤—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º"""
    print(f"\nüîß WINSORIZING –î–õ–Ø {df_name}:")
    
    # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∏—Å–∫–ª—é—á–∞—è —Ü–µ–ª–µ–≤—É—é –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ)
    numeric_features = df.select_dtypes(include=[np.number]).columns
    numeric_features = [col for col in numeric_features if col != 'total_UPDRS' and col != 'sex']
    
    for feature in numeric_features:
        original_skew = df[feature].skew()
        # Winsorize –≤–µ—Ä—Ö–Ω–∏–µ –∏ –Ω–∏–∂–Ω–∏–µ 2%
        df[feature] = winsorize(df[feature], limits=[0.02, 0.02])
        new_skew = df[feature].skew()
        
        if abs(original_skew - new_skew) > 0.5:  # –ï—Å–ª–∏ –∞—Å–∏–º–º–µ—Ç—Ä–∏—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏–ª–∞—Å—å
            print(f"  ‚úÖ {feature}: –∞—Å–∏–º–º–µ—Ç—Ä–∏—è {original_skew:.2f} ‚Üí {new_skew:.2f}")

# –ü—Ä–∏–º–µ–Ω—è–µ–º winsorizing –∫ –æ–±–æ–∏–º –¥–∞—Ç–∞—Å–µ—Ç–∞–º
apply_winsorizing(df_full, 'df_full')
apply_winsorizing(df_reduced, 'df_reduced')

B.4 –û–ë–†–ê–ë–û–¢–ö–ê –í–´–ë–†–û–°–û–í (WINSORIZE)
----------------------------------------

üîß WINSORIZING –î–õ–Ø df_full:
  ‚úÖ Jitter(%): –∞—Å–∏–º–º–µ—Ç—Ä–∏—è 6.45 ‚Üí 2.28
  ‚úÖ Jitter:RAP: –∞—Å–∏–º–º–µ—Ç—Ä–∏—è 6.95 ‚Üí 2.32
  ‚úÖ Jitter:PPQ5: –∞—Å–∏–º–º–µ—Ç—Ä–∏—è 7.59 ‚Üí 2.43
  ‚úÖ Jitter:DDP: –∞—Å–∏–º–º–µ—Ç—Ä–∏—è 6.95 ‚Üí 2.31
  ‚úÖ Shimmer: –∞—Å–∏–º–º–µ—Ç—Ä–∏—è 3.31 ‚Üí 2.21
  ‚úÖ Shimmer(dB): –∞—Å–∏–º–º–µ—Ç—Ä–∏—è 3.10 ‚Üí 2.21
  ‚úÖ Shimmer:APQ3: –∞—Å–∏–º–º–µ—Ç—Ä–∏—è 3.10 ‚Üí 1.89
  ‚úÖ Shimmer:APQ5: –∞—Å–∏–º–º–µ—Ç—Ä–∏—è 3.70 ‚Üí 2.20
  ‚úÖ Shimmer:APQ11: –∞—Å–∏–º–º–µ—Ç—Ä–∏—è 3.41 ‚Üí 1.92
  ‚úÖ Shimmer:DDA: –∞—Å–∏–º–º–µ—Ç—Ä–∏—è 3.10 ‚Üí 1.89
  ‚úÖ NHR: –∞—Å–∏–º–º–µ—Ç—Ä–∏—è 6.55 ‚Üí 3.50

üîß WINSORIZING –î–õ–Ø df_reduced:
  ‚úÖ shimmer_combined: –∞—Å–∏–º–º–µ—Ç—Ä–∏—è 3.10 ‚Üí 2.12
  ‚úÖ jitter_combined: –∞—Å–∏–º–º–µ—Ç—Ä–∏—è 6.88 ‚Üí 2.38
  ‚úÖ NHR: –∞—Å–∏–º–º–µ—Ç—Ä–∏—è 6.55 ‚Üí 3.50


print("\nB.5 –ü–†–û–í–ï–†–ö–ê –ú–£–õ–¨–¢–ò–ö–û–õ–õ–ò–ù–ï–ê–†–ù–û–°–¢–ò")
print("-" * 40)

def check_multicollinearity(df, df_name):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    print(f"\nüîç –ü–†–û–í–ï–†–ö–ê –ú–£–õ–¨–¢–ò–ö–û–õ–õ–ò–ù–ï–ê–†–ù–û–°–¢–ò –î–õ–Ø {df_name}:")
    
    # –£–¥–∞–ª—è–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    X = df.drop('total_UPDRS', axis=1)
    
    # –£–î–ê–õ–Ø–ï–ú Jitter(Abs) –∏–∑ df_full –∫–∞–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ
    if df_name == 'df_full' and 'Jitter(Abs)' in X.columns:
        X = X.drop('Jitter(Abs)', axis=1)
        print("‚úÖ Jitter(Abs) —É–¥–∞–ª–µ–Ω –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ (49.9% –ø—Ä–æ–ø—É—Å–∫–æ–≤)")
    
    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É
    corr_matrix = X.corr().abs()
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä—ã
    high_corr_pairs = []
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            if corr_matrix.iloc[i, j] > 0.8:  # –ü–æ—Ä–æ–≥ 0.8 –¥–ª—è —Å–∏–ª—å–Ω–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
                col1, col2 = corr_matrix.columns[i], corr_matrix.columns[j]
                corr_value = corr_matrix.iloc[i, j]
                high_corr_pairs.append((col1, col2, corr_value))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∏–ª–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
    high_corr_pairs.sort(key=lambda x: x[2], reverse=True)
    
    if high_corr_pairs:
        print(f"üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(high_corr_pairs)} –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä (corr > 0.8):")
        for col1, col2, corr_value in high_corr_pairs:
            print(f"  {col1} - {col2}: {corr_value:.3f}")
    else:
        print("‚úÖ –í—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ (corr < 0.8)")
    
    return high_corr_pairs

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å –¥–ª—è –æ–±–æ–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
multicollinearity_full = check_multicollinearity(df_full, 'df_full')
multicollinearity_reduced = check_multicollinearity(df_reduced, 'df_reduced')

print("\nB.6 –†–ê–ó–î–ï–õ–ï–ù–ò–ï –ù–ê –í–´–ë–û–†–ö–ò")
print("-" * 40)

def create_train_val_test_splits(df, test_size=0.2, val_size=0.2, random_state=42):
    """–°–æ–∑–¥–∞–µ—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ –≤—ã–±–æ—Ä–∫–∏"""
    X = df.drop('total_UPDRS', axis=1)
    y = df['total_UPDRS']
    
    # –ü–µ—Ä–≤–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: –≤—Ä–µ–º–µ–Ω–Ω–∞—è –∏ —Ç–µ—Å—Ç–æ–≤–∞—è
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, shuffle=True
    )
    
    # –í—Ç–æ—Ä–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: –æ–±—É—á–∞—é—â–∞—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è
    val_relative_size = val_size / (1 - test_size)
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=val_relative_size, random_state=random_state, shuffle=True
    )
    
    return X_train, X_val, X_test, y_train, y_val, y_test

# –°–æ–∑–¥–∞–µ–º —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –æ–±–æ–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
print("–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫...")

X_train_full, X_val_full, X_test_full, y_train_full, y_val_full, y_test_full = create_train_val_test_splits(df_full)
X_train_red, X_val_red, X_test_red, y_train_red, y_val_red, y_test_red = create_train_val_test_splits(df_reduced)

print("‚úÖ –†–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ –≤—ã–±–æ—Ä–∫–∏ —Å–æ–∑–¥–∞–Ω—ã:")
print(f"  df_full: train={X_train_full.shape[0]}, val={X_val_full.shape[0]}, test={X_test_full.shape[0]}")
print(f"  df_reduced: train={X_train_red.shape[0]}, val={X_val_red.shape[0]}, test={X_test_red.shape[0]}")


B.6 –†–ê–ó–î–ï–õ–ï–ù–ò–ï –ù–ê –í–´–ë–û–†–ö–ò
----------------------------------------
–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫...
‚úÖ –†–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ –≤—ã–±–æ—Ä–∫–∏ —Å–æ–∑–¥–∞–Ω—ã:
  df_full: train=3525, val=1175, test=1175
  df_reduced: train=3525, val=1175, test=1175

print("\nB.7 –ü–†–û–í–ï–†–ö–ê –ù–ê –ü–†–û–ü–£–©–ï–ù–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø")
print("-" * 40)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –ø—Ä–æ–ø—É—Å–∫–∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω—ã
print("–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –≤—ã–±–æ—Ä–∫–∞—Ö:")

print(f"\ndf_full:")
print(f"  X_train: {X_train_full.isnull().sum().sum()} –ø—Ä–æ–ø—É—Å–∫–æ–≤")
print(f"  X_val: {X_val_full.isnull().sum().sum()} –ø—Ä–æ–ø—É—Å–∫–æ–≤")
print(f"  X_test: {X_test_full.isnull().sum().sum()} –ø—Ä–æ–ø—É—Å–∫–æ–≤")

print(f"\ndf_reduced:")
print(f"  X_train: {X_train_red.isnull().sum().sum()} –ø—Ä–æ–ø—É—Å–∫–æ–≤")
print(f"  X_val: {X_val_red.isnull().sum().sum()} –ø—Ä–æ–ø—É—Å–∫–æ–≤")
print(f"  X_test: {X_test_red.isnull().sum().sum()} –ø—Ä–æ–ø—É—Å–∫–æ–≤")


B.7 –ü–†–û–í–ï–†–ö–ê –ù–ê –ü–†–û–ü–£–©–ï–ù–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø
----------------------------------------
–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –≤—ã–±–æ—Ä–∫–∞—Ö:

df_full:
  X_train: 0 –ø—Ä–æ–ø—É—Å–∫–æ–≤
  X_val: 0 –ø—Ä–æ–ø—É—Å–∫–æ–≤
  X_test: 0 –ø—Ä–æ–ø—É—Å–∫–æ–≤

df_reduced:
  X_train: 0 –ø—Ä–æ–ø—É—Å–∫–æ–≤
  X_val: 0 –ø—Ä–æ–ø—É—Å–∫–æ–≤
  X_test: 0 –ø—Ä–æ–ø—É—Å–∫–æ–≤

# –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è B.8 (–ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ)
X_train_full_imp = X_train_full
X_val_full_imp = X_val_full
X_test_full_imp = X_test_full

X_train_red_imp = X_train_red
X_val_red_imp = X_val_red
X_test_red_imp = X_test_red

# =============================================================================
# B.8 –°–û–ó–î–ê–ù–ò–ï –°–¢–ê–ù–î–ê–†–¢–ò–ó–ò–†–û–í–ê–ù–ù–´–• –í–ï–†–°–ò–ô
# =============================================================================

print("\nB.8 –°–û–ó–î–ê–ù–ò–ï –°–¢–ê–ù–î–ê–†–¢–ò–ó–ò–†–û–í–ê–ù–ù–´–• –í–ï–†–°–ò–ô")
print("-" * 40)

def apply_standard_scaling(X_train, X_val, X_test):
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é"""
    scaler = StandardScaler()
    
    # Fit –¢–û–õ–¨–ö–û –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    X_train_scaled = scaler.fit_transform(X_train)
    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)
    
    # Transform –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    X_val_scaled = scaler.transform(X_val)
    X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns, index=X_val.index)
    
    X_test_scaled = scaler.transform(X_test)
    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)
    
    return X_train_scaled, X_val_scaled, X_test_scaled, scaler

print("–°–æ–∑–¥–∞–Ω–∏–µ 4 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤...")

# 1. –ü–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä (–±–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏)
dataset1 = {
    'X_train': X_train_full_imp, 'X_val': X_val_full_imp, 'X_test': X_test_full_imp,
    'y_train': y_train_full, 'y_val': y_val_full, 'y_test': y_test_full,
    'name': '–ü–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä (–±–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏)',
    'features': X_train_full_imp.columns.tolist(),
    'source': 'df_full'
}

# 2. –ü–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä + —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è
X_train_full_std, X_val_full_std, X_test_full_std, scaler_full = apply_standard_scaling(
    X_train_full_imp, X_val_full_imp, X_test_full_imp)
dataset2 = {
    'X_train': X_train_full_std, 'X_val': X_val_full_std, 'X_test': X_test_full_std,
    'y_train': y_train_full, 'y_val': y_val_full, 'y_test': y_test_full,
    'name': '–ü–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä + —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è',
    'features': X_train_full_std.columns.tolist(),
    'scaler': scaler_full,
    'source': 'df_full'
}

# 3. –°–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä (–±–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏)
dataset3 = {
    'X_train': X_train_red_imp, 'X_val': X_val_red_imp, 'X_test': X_test_red_imp,
    'y_train': y_train_red, 'y_val': y_val_red, 'y_test': y_test_red,
    'name': '–°–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä (–±–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏)',
    'features': X_train_red_imp.columns.tolist(),
    'source': 'df_reduced'
}

# 4. –°–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä + —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è
X_train_red_std, X_val_red_std, X_test_red_std, scaler_red = apply_standard_scaling(
    X_train_red_imp, X_val_red_imp, X_test_red_imp)
dataset4 = {
    'X_train': X_train_red_std, 'X_val': X_val_red_std, 'X_test': X_test_red_std,
    'y_train': y_train_red, 'y_val': y_val_red, 'y_test': y_test_red,
    'name': '–°–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä + —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è',
    'features': X_train_red_std.columns.tolist(),
    'scaler': scaler_red,
    'source': 'df_reduced'
}

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
datasets = {
    'full': dataset1,
    'full_std': dataset2, 
    'reduced': dataset3,
    'reduced_std': dataset4
}

print("\nüìã –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–í–û–î–ö–ê:")
for key, dataset in datasets.items():
    print(f"\n{dataset['name']}:")
    print(f"  ‚Ä¢ –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(dataset['features'])}")
    print(f"  ‚Ä¢ –†–∞–∑–º–µ—Ä—ã: train={dataset['X_train'].shape}, val={dataset['X_val'].shape}, test={dataset['X_test'].shape}")
    print(f"  ‚Ä¢ –ü—Ä–∏–∑–Ω–∞–∫–∏: {dataset['features']}")

B.8 –°–û–ó–î–ê–ù–ò–ï –°–¢–ê–ù–î–ê–†–¢–ò–ó–ò–†–û–í–ê–ù–ù–´–• –í–ï–†–°–ò–ô
----------------------------------------
–°–æ–∑–¥–∞–Ω–∏–µ 4 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤...

üìã –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–í–û–î–ö–ê:

–ü–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä (–±–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏):
  ‚Ä¢ –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: 18
  ‚Ä¢ –†–∞–∑–º–µ—Ä—ã: train=(3525, 18), val=(1175, 18), test=(1175, 18)
  ‚Ä¢ –ü—Ä–∏–∑–Ω–∞–∫–∏: ['age', 'sex', 'test_time', 'Jitter(%)', 'Jitter:RAP', 'Jitter:PPQ5', 'Jitter:DDP', 'Shimmer', 'Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5', 'Shimmer:APQ11', 'Shimmer:DDA', 'NHR', 'HNR', 'RPDE', 'DFA', 'PPE']

–ü–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä + —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è:
  ‚Ä¢ –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: 18
  ‚Ä¢ –†–∞–∑–º–µ—Ä—ã: train=(3525, 18), val=(1175, 18), test=(1175, 18)
  ‚Ä¢ –ü—Ä–∏–∑–Ω–∞–∫–∏: ['age', 'sex', 'test_time', 'Jitter(%)', 'Jitter:RAP', 'Jitter:PPQ5', 'Jitter:DDP', 'Shimmer', 'Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5', 'Shimmer:APQ11', 'Shimmer:DDA', 'NHR', 'HNR', 'RPDE', 'DFA', 'PPE']

–°–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä (–±–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏):
  ‚Ä¢ –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: 10
  ‚Ä¢ –†–∞–∑–º–µ—Ä—ã: train=(3525, 10), val=(1175, 10), test=(1175, 10)
  ‚Ä¢ –ü—Ä–∏–∑–Ω–∞–∫–∏: ['age', 'sex', 'test_time', 'shimmer_combined', 'jitter_combined', 'NHR', 'HNR', 'RPDE', 'DFA', 'PPE']

–°–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä + —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è:
  ‚Ä¢ –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: 10
  ‚Ä¢ –†–∞–∑–º–µ—Ä—ã: train=(3525, 10), val=(1175, 10), test=(1175, 10)
  ‚Ä¢ –ü—Ä–∏–∑–Ω–∞–∫–∏: ['age', 'sex', 'test_time', 'shimmer_combined', 'jitter_combined', 'NHR', 'HNR', 'RPDE', 'DFA', 'PPE']

# =============================================================================
# B.9 –ü–û–î–ì–û–¢–û–í–ö–ê –î–õ–Ø –ù–ï–ô–†–û–°–ï–¢–ï–ô (MLP, CNN, LSTM)
# =============================================================================

print("\nB.9 –ü–û–î–ì–û–¢–û–í–ö–ê –î–õ–Ø –ù–ï–ô–†–û–°–ï–¢–ï–ô")
print("-" * 40)

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ NumPy arrays –¥–ª—è TensorFlow/Keras
for key in datasets.keys():
    dataset = datasets[key]
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy arrays –¥–ª—è MLP
    dataset['X_train_array'] = dataset['X_train'].values.astype('float32')
    dataset['X_val_array'] = dataset['X_val'].values.astype('float32')
    dataset['X_test_array'] = dataset['X_test'].values.astype('float32')
    dataset['y_train_array'] = dataset['y_train'].values.astype('float32')
    dataset['y_val_array'] = dataset['y_val'].values.astype('float32')
    dataset['y_test_array'] = dataset['y_test'].values.astype('float32')
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–ª—è 1D CNN (–¥–æ–±–∞–≤–ª—è–µ–º dimension –¥–ª—è –∫–∞–Ω–∞–ª–æ–≤)
    dataset['X_train_cnn'] = dataset['X_train_array'].reshape(dataset['X_train_array'].shape[0], 
                                                             dataset['X_train_array'].shape[1], 1)
    dataset['X_val_cnn'] = dataset['X_val_array'].reshape(dataset['X_val_array'].shape[0], 
                                                         dataset['X_val_array'].shape[1], 1)
    dataset['X_test_cnn'] = dataset['X_test_array'].reshape(dataset['X_test_array'].shape[0], 
                                                           dataset['X_test_array'].shape[1], 1)
    
    print(f"‚úÖ {key}:")
    print(f"   MLP arrays: {dataset['X_train_array'].shape}")
    print(f"   CNN arrays: {dataset['X_train_cnn'].shape}")


B.9 –ü–û–î–ì–û–¢–û–í–ö–ê –î–õ–Ø –ù–ï–ô–†–û–°–ï–¢–ï–ô
----------------------------------------
‚úÖ full:
   MLP arrays: (3525, 18)
   CNN arrays: (3525, 18, 1)
‚úÖ full_std:
   MLP arrays: (3525, 18)
   CNN arrays: (3525, 18, 1)
‚úÖ reduced:
   MLP arrays: (3525, 10)
   CNN arrays: (3525, 10, 1)
‚úÖ reduced_std:
   MLP arrays: (3525, 10)
   CNN arrays: (3525, 10, 1)
